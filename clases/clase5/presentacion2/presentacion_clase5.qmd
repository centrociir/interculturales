---
title: "AnÃ¡lisis cuantitativo del texto"
subtitle: "Seminario: InteRculturales"
author: "MatÃ­as Deneken"
logo: "images/logo_ciir.jpg"
include-in-header:
  - text: |
      <style>
        .reveal .slides {
          padding-top: 0px !important;
        }
        .reveal h2 {
          margin-top: -20px !important;
        }
      </style>
footer: "SesiÃ³n 3: InteRculturales"
date: "2025-05-22"
date-format: long
format: 
  revealjs:
    incremental: true
    theme: simple
    width: 1600
    height: 900
    transition: slide
    slide-number: c/t
    chalkboard: true
    auto-stretch: false
callout-appearance: minimal
---

```{r, eval=TRUE}
library(tidyverse)
library(sf)
library(countrycode)
library(chilemapas)
```

# Â¿QuÃ© veremos hoy?

1.  Â¿CÃ³mo hacer cosas con las palabras?
2.  La minerÃ­a de texto: DesafÃ­o de las Ciencias Sociales Computacionales
3.  Conceptos claves
4.  Uso y prÃ¡ctica en el software R
    a.  Palabras en su contexto
    b.  Paquete Quanteda
    c.  Tidytext
5.  Preguntas empÃ­ricas

## Resultados esperados {.smaller}

::: columns
::: {.column width="50%"}
### Nube de las palabras ğŸ¥±

![](images/humilde-objetivo1.png){fig-align="center" width="564" height="435"}
:::

::: {.column width="50%"}
### Tendencias de palabras

![](images/humilde-objetivo2.png){fig-align="center" width="666"}
:::
:::

## Â¿CÃ³mo hacer cosas con las palabras?

```         
Pues bien; si a un cervantista se le ocurriera decir: el Quijote empieza con dos palabras monosilÃ¡bicas terminadas en n: (en y un), y sigue con una de cinco letras (lugar), con dos de dos letras (de la), con una de cinco o de seis (Mancha), y luego se le ocurriera derivar conclusiones de eso, inmediatamente se pensarÃ­a que estÃ¡ loco. La Biblia ha sido estudiada de ese modo.
```

```         
Jorge Luis Borges en "La CÃ¡bala". Conferencias denominadas Siete Noches
```

![](img/borges.jpg){fig-align="center" width="579"}

## Â¿CÃ³mo hacer cosas con la palabras?

### Â¿Y lo podremos hacer?

<p style="font-size: 24px; text-align: center;">

[En]{style="color: red;"} [un]{style="color: blue;"} [lugar]{style="color: black;"} [de]{style="color: green;"} [la]{style="color: purple;"} [Mancha,]{style="color: black;"} [de]{style="color: red;"} [cuyo]{style="color: black;"} [nombre]{style="color: black;"} [no]{style="color: blue;"} [quiero]{style="color: black;"} [acordarme]{style="color: brown;"}.

</p>

<p style="font-size: 18px; text-align: center;">

[(1)]{style="color: red;"} [(1)]{style="color: blue;"} [(2)]{style="color: black;"} [(1)]{style="color: green;"} [(1)]{style="color: purple;"} [(2)]{style="color: black;"} [(1)]{style="color: red;"} [(2)]{style="color: brown;"} [(2)]{style="color: black;"} [(1)]{style="color: blue;"} [(2)]{style="color: black;"} [(4)]{style="color: brown;"}

</p>

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Crear la secuencia
secuencia <- c(1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 4)

# Crear un grÃ¡fico de lÃ­neas
plot(secuencia, type = "o", pch = 16, lwd = 2,
     xlab = "PosiciÃ³n en la secuencia", ylab = "Valor",
     main = "GrÃ¡fico de la secuencia (1)(1)(2)(1)(1)(2)...")

# Agregar lÃ­neas de referencia
abline(h = unique(secuencia), col = "gray", lty = 3)

```

## CÃ³mo hacer cosas con la palabras.

::: columns
::: {.column width="50%"}
### DenotaciÃ³n y la connotaciÃ³n

![](img/guerra-pinera.jpg){width="100%"}
:::

::: {.column width="50%"}
### Palabras y sus efectos

![](img/biden1.jpg){width="52%"}

<br> <!-- espacio entre imÃ¡genes -->

![](img/biden2.jpg){width="56%"}
:::
:::

## Ciencias Sociales Computacionales: *Text Mining*

LasÂ **Ciencias Sociales Computacionales**Â integran herramientas de la computaciÃ³n con preguntas sustantivas de las ciencias sociales. En este cruce, elÂ **text mining**Â (minerÃ­a de texto) permite analizar grandes volÃºmenes de texto â€”como discursos, noticias o redes socialesâ€” para identificar patrones, temas, emociones o relaciones entre actores.

MÃ¡s que contar palabras, se trata deÂ **convertir texto en datos estructurados**Â que permitan nuevas formas de interpretar lo social.

Esta metodologÃ­a abre nuevas posibilidades para:

1.  ExplorarÂ **tendencias discursivas**Â en el tiempo.
2.  IdentificarÂ **marcos ideolÃ³gicos**Â y emociones dominantes.
3.  Analizar cÃ³mo ciertos conceptos (comoÂ *desigualdad*,Â *democracia*,Â *identidad*) aparecen y se transforman en distintos contextos.

## Ciencias Sociales Computacionales: *Text Mining*

ElÂ **Procesamiento de Lenguaje Natural**Â (en inglÃ©s,Â *Natural Language Processing*, NLP) es un campo interdisciplinario entreÂ **lingÃ¼Ã­stica**,Â **ciencia computacional**Â eÂ **inteligencia artificial**, que busca desarrollar mÃ©todos para que las mÃ¡quinas puedanÂ **leer, interpretar, generar y analizar lenguaje humano**Â (oral o escrito).

Incluye tareas como:

-   **TokenizaciÃ³n**: dividir el texto en palabras, frases o unidades mÃ­nimas.

-   **LematizaciÃ³n/Stemming**: reducir palabras a su forma base ("corriendo" â†’ "correr").

-   **AnÃ¡lisis sintÃ¡ctico y semÃ¡ntico**: entender la estructura gramatical o el significado del texto.

-   **ExtracciÃ³n de entidades**Â (personas, lugares, organizaciones).

-   **ClasificaciÃ³n de sentimientos**, detecciÃ³n de tÃ³picos, generaciÃ³n de texto, etc.

## Ciencias Sociales Computacionales: *Text Mining*

Algunos ejemplos de tÃ©cnicas.

-   Modelos de tÃ³picos (LDA) â†’ para identificar temas latentes en discursos.

-   AnÃ¡lisis de sentimiento â†’ para mapear emociones o polarizaciÃ³n.

-   Redes semÃ¡nticas â†’ para ver cÃ³mo se asocian conceptos o actores.

-   Clasificadores supervisados â†’ para categorizar tweets, artÃ­culos o comentarios por tipo, ideologÃ­a, tono, etc.

## Ciencias Sociales Computacionales: *Text Mining*

**Â¿CÃ³mo ha cambiado la forma en que los presidentes de Chile hablan sobre la *desigualdad* entre 1990 y 2021?**

-   ğŸ“„ **Corpus**: Discursos anuales de la Cuenta PÃºblica (1990â€“2021)\
-   ğŸ” **Filtro por concepto**: Palabras como `desigual*`, `brecha*`, `inequidad`, `estratificaciÃ³n`\
-   ğŸ“Š **Conteo por aÃ±o**: NÃºmero de menciones por discurso\
-   ğŸ“ˆ **VisualizaciÃ³n**: GrÃ¡fico de lÃ­nea para mostrar evoluciÃ³n

**Â¿Por quÃ© es Ãºtil?**

-   Convierte texto cualitativo en **datos analizables**\
-   Permite comparaciones temporales y temÃ¡ticas\
-   Une teorÃ­a social y herramientas computacionales

## Fundamento en R

#### ğŸ§° Paquetes esenciales

-   ğŸ“¦ **`quanteda`**
    -   Corpus estructurados (`corpus()`, `tokens()`, `dfm()`)
    -   AnÃ¡lisis por diccionario (`dictionary()`, `dfm_lookup()`)
    -   KWIC y anÃ¡lisis de contexto (`kwic()`)
-   ğŸ“¦ **`tidytext`**
    -   IntegraciÃ³n con `dplyr` para limpieza y visualizaciÃ³n
    -   Compatible con enfoques Tidy: `count()`, `mutate()`, `group_by()`

#### ğŸ—‚ï¸ Uso de diccionarios

-   Permite **agrupar palabras en categorÃ­as temÃ¡ticas**
-   Se pueden usar para:
    -   Filtrar palabras por tema o emociÃ³n
    -   Medir frecuencia relativa o presencia/ausencia

# Conceptos y funciones fundamentales

```{r, echo=TRUE}
# Texto base
texto <- "Desde 1990 Chile es una democracia representativa y Chile 
es libre. A lo largo de su historia, Chile se 
destacÃ³ por su estabilibidad democrÃ¡tica, siendo la excepciÃ³n la dictadura de Pinochet"
```

## Conceptos y funciones fundamentales

### ğŸ§± Token

> UnÂ **token**Â es una unidad mÃ­nima de anÃ¡lisis, usualmente una palabra. Tokenizar un texto significaÂ **dividirlo en esas unidades**.

```{r}
#| eval: true
#| echo: true

library(quanteda)
corp <- corpus(texto)
tokens(corp)


```

## ğŸ”¡ DFM (Document-Feature Matrix)

> UnaÂ **DFM**Â es una matriz donde cada fila representa un documento y cada columna una palabra Ãºnica (token). El valor es la frecuencia.

```{r}
#| eval: true
#| echo: true


dfm(tokens(corp))
```

-   `"chile"`Â apareceÂ **2 veces**

-   `"es"`Â apareceÂ **2 veces**

-   Las demÃ¡s palabras (`una`,Â `democracia`,Â `representativa`,Â `y`,Â `libre`,Â `"."`) aparecenÂ **una vez cada una**

-   El puntoÂ `"."`Â fue considerado como un token separado (esto ocurre si no se removiÃ³ la puntuaciÃ³n al crear los tokens)

## ğŸ”¡ DFM (Document-Feature Matrix): Remove punct

```{r}
#| eval: true
#| echo: true


tokens_reducidos <- tokens(corp, remove_punct = TRUE) %>%
  tokens_tolower() %>%  # pasar a minÃºsculas
  tokens_wordstem(language = "spanish")  # aplicar stemming

tokens_reducidos


```

## Sobre los bigramas

```{r}
#| eval: true
#| echo: true

library(tidytext)
library(tibble)
bigrama <- tibble(text = texto) %>%
  unnest_tokens(bigrama, text, token = "ngrams", n = 2)

bigrama

```

## KWIC y Stemming

### ğŸ” KWIC (Key Word in Context)

> Muestra las palabrasÂ **inmediatamente antes y despuÃ©s**Â de una palabra clave. Es Ãºtil paraÂ **analizar el contexto semÃ¡ntico**.

```{r}
#| eval: true
#| echo: true


kwic(tokens(corp), pattern = "Chile", window = 2)

```

## Ruido de palabras

### ğŸš« Â¿QuÃ© es una *Stop Word*?

> Son palabras muy frecuentes (como **"el", "de", "y", "es"**) que usualmente **no aportan significado sustantivo** al anÃ¡lisis textual.

### ğŸ§  Â¿Por quÃ© eliminarlas?

-   Aparecen en casi todos los textos â†’ **ruido analÃ­tico**
-   No discriminan entre temas ni emociones
-   Permite centrarse en contenido mÃ¡s relevante (sustantivos, verbos clave)

```{r}
#| eval: true
#| echo: true


library(quanteda)

tokens_limpios <-tokens(texto,
       remove_punct = TRUE) %>%                 # Elimina puntos, comas, etc.
  tokens_tolower() %>%                          # Convierte a minÃºsculas
  tokens_remove(pattern = stopwords("spanish")) # Elimina stop words en espaÃ±ol

tokens_limpios

```

## â˜ï¸ Nube de palabras desde texto limpio

> Eliminamos puntuaciÃ³n y stop words para visualizar solo las palabras relevantes.

```{r}
#| eval: true
#| echo: true


library(quanteda.textplots)

# Texto mÃ¡s largo
texto <- "Chile es una democracia representativa. El paÃ­s enfrenta desigualdades, pero tambiÃ©n oportunidades. La educaciÃ³n, la salud y el trabajo son temas prioritarios para Chile."

# Limpiar y procesar
tokens_limpios <- tokens(texto,
                         remove_punct = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(pattern = stopwords("spanish"))

```

### Crear dfm (document-feature matrix)

```{r}
#| eval: true
#| echo: true

dfm_limpio <- dfm(tokens_limpios); dfm_limpio
```

## â˜ï¸ Nube de palabras desde texto limpio

### Visualizar

```{r}
#| eval: true
#| echo: true

# Nube de palabras mÃ¡s rica
textplot_wordcloud(dfm_limpio, max_words = 50, min_count = 1)
```

## Diccionarios

Pensemos en un texto.

```{r}
#| echo: true
#| eval: true
library(tidytext)
library(stringr)

texto <- "La democracia es fundamental para la participaciÃ³n ciudadana. 
Sin embargo, la delincuencia organizada y el narcotrÃ¡fico han aumentado. Se ha generado un escenario de inseguridad.
La migraciÃ³n tambiÃ©n es un desafÃ­o que debe abordarse con polÃ­ticas pÃºblicas integradas y garantizar derechos bÃ¡sicos."

```

Â¿QuÃ© conceptos no pueden parecer interesantes? Definimos palabras previas.

```{r}
#| echo: true
#| eval: true

# Texto de ejemplo
texto <- "La democracia es clave. La delincuencia y el narcotrÃ¡fico afectan la ciudadanÃ­a. 
Muchos migrantes y refugiados llegaron en 2023."

# Diccionario con comodines
diccionario_temas <- list(
  democracia = c("democracia", "participaciÃ³n", "ciudad*", "instituciones", "elecciones", "derecho*"),
  delincuencia = c("delincuencia", "crimen", "inseguridad", "violencia", "narco*"),
  migracion = c("migra*",  "refugiado", "exilio", "inmigraciÃ³n")
)
```

## Diccionarios

```{r}
# Tokenizar texto usando tidytext
tokens_df <- tibble(text = texto) %>%
  unnest_tokens(word, text) %>%
  filter(str_detect(word, "^[a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+$"))

```

```{r}
#| echo: true
#| eval: true

# Aplicar diccionario con comodines
patrones_democracia <- str_replace_all(diccionario_temas$democracia, "\\*", ".*")
patrones_delincuencia <- str_replace_all(diccionario_temas$delincuencia, "\\*", ".*")
patrones_migracion <- str_replace_all(diccionario_temas$migracion, "\\*", ".*")

tokens_clasificados <- tokens_df %>%
  mutate(
    tema = case_when(
      str_detect(word, regex(paste0("^(", paste(patrones_democracia, collapse = "|"), ")$"), ignore_case = TRUE)) ~ "democracia",
      str_detect(word, regex(paste0("^(", paste(patrones_delincuencia, collapse = "|"), ")$"), ignore_case = TRUE)) ~ "delincuencia",
      str_detect(word, regex(paste0("^(", paste(patrones_migracion, collapse = "|"), ")$"), ignore_case = TRUE)) ~ "migracion",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(tema)) %>%
  count(tema, word, sort = TRUE)

```

```{r}
tokens_clasificados

```

## Diccionarios

```{r}
#| echo: true
#| eval: true

library(ggplot2)

ggplot(tokens_clasificados, aes(x = reorder_within(word, n, tema), y = n, fill = tema)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ tema, scales = "free_y") +
  scale_x_reordered() +
  coord_flip() +
  labs(
    title = "Palabras clave por tema detectadas en el texto",
    subtitle = "Basado en un diccionario con comodines",
    x = NULL, y = "Frecuencia"
  ) 
```

# Vamos al cÃ³digo!
