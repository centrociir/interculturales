---
title: "Análisis cuantitativo del texto"
subtitle: "Seminario: InteRculturales"
author: "Matías Deneken"
logo: "images/logo_ciir.jpg"
include-in-header:
  - text: |
      <style>
        .reveal .slides {
          padding-top: 0px !important;
        }
        .reveal h2 {
          margin-top: -20px !important;
        }
      </style>
footer: "Sesión 3: InteRculturales"
date: "2025-05-22"
date-format: long
format: 
  revealjs:
    incremental: true
    theme: simple
    width: 1600
    height: 900
    transition: slide
    slide-number: c/t
    chalkboard: true
    auto-stretch: false
callout-appearance: minimal
---

```{r, eval=TRUE}
library(tidyverse)
library(sf)
library(countrycode)
library(chilemapas)
```

# ¿Qué veremos hoy?

1.  ¿Cómo hacer cosas con las palabras?
2.  La minería de texto: Desafío de las Ciencias Sociales Computacionales
3.  Conceptos claves
4.  Uso y práctica en el software R
    a.  Palabras en su contexto
    b.  Paquete Quanteda
    c.  Tidytext
5.  Preguntas empíricas

## Resultados esperados {.smaller}

::: columns
::: {.column width="50%"}
### Nube de las palabras 🥱

![](images/humilde-objetivo1.png){fig-align="center" width="564" height="435"}
:::

::: {.column width="50%"}
### Tendencias de palabras

![](images/humilde-objetivo2.png){fig-align="center" width="666"}
:::
:::

## ¿Cómo hacer cosas con las palabras?

```         
Pues bien; si a un cervantista se le ocurriera decir: el Quijote empieza con dos palabras monosilábicas terminadas en n: (en y un), y sigue con una de cinco letras (lugar), con dos de dos letras (de la), con una de cinco o de seis (Mancha), y luego se le ocurriera derivar conclusiones de eso, inmediatamente se pensaría que está loco. La Biblia ha sido estudiada de ese modo.
```

```         
Jorge Luis Borges en "La Cábala". Conferencias denominadas Siete Noches
```

![](img/borges.jpg){fig-align="center" width="579"}

## ¿Cómo hacer cosas con la palabras?

### ¿Y lo podremos hacer?

<p style="font-size: 24px; text-align: center;">

[En]{style="color: red;"} [un]{style="color: blue;"} [lugar]{style="color: black;"} [de]{style="color: green;"} [la]{style="color: purple;"} [Mancha,]{style="color: black;"} [de]{style="color: red;"} [cuyo]{style="color: black;"} [nombre]{style="color: black;"} [no]{style="color: blue;"} [quiero]{style="color: black;"} [acordarme]{style="color: brown;"}.

</p>

<p style="font-size: 18px; text-align: center;">

[(1)]{style="color: red;"} [(1)]{style="color: blue;"} [(2)]{style="color: black;"} [(1)]{style="color: green;"} [(1)]{style="color: purple;"} [(2)]{style="color: black;"} [(1)]{style="color: red;"} [(2)]{style="color: brown;"} [(2)]{style="color: black;"} [(1)]{style="color: blue;"} [(2)]{style="color: black;"} [(4)]{style="color: brown;"}

</p>

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Crear la secuencia
secuencia <- c(1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 4)

# Crear un gráfico de líneas
plot(secuencia, type = "o", pch = 16, lwd = 2,
     xlab = "Posición en la secuencia", ylab = "Valor",
     main = "Gráfico de la secuencia (1)(1)(2)(1)(1)(2)...")

# Agregar líneas de referencia
abline(h = unique(secuencia), col = "gray", lty = 3)

```

## Cómo hacer cosas con la palabras.

::: columns
::: {.column width="50%"}
### Denotación y la connotación

![](img/guerra-pinera.jpg){width="100%"}
:::

::: {.column width="50%"}
### Palabras y sus efectos

![](img/biden1.jpg){width="52%"}

<br> <!-- espacio entre imágenes -->

![](img/biden2.jpg){width="56%"}
:::
:::

## Ciencias Sociales Computacionales: *Text Mining*

Las **Ciencias Sociales Computacionales** integran herramientas de la computación con preguntas sustantivas de las ciencias sociales. En este cruce, el **text mining** (minería de texto) permite analizar grandes volúmenes de texto —como discursos, noticias o redes sociales— para identificar patrones, temas, emociones o relaciones entre actores.

Más que contar palabras, se trata de **convertir texto en datos estructurados** que permitan nuevas formas de interpretar lo social.

Esta metodología abre nuevas posibilidades para:

1.  Explorar **tendencias discursivas** en el tiempo.
2.  Identificar **marcos ideológicos** y emociones dominantes.
3.  Analizar cómo ciertos conceptos (como *desigualdad*, *democracia*, *identidad*) aparecen y se transforman en distintos contextos.

## Ciencias Sociales Computacionales: *Text Mining*

El **Procesamiento de Lenguaje Natural** (en inglés, *Natural Language Processing*, NLP) es un campo interdisciplinario entre **lingüística**, **ciencia computacional** e **inteligencia artificial**, que busca desarrollar métodos para que las máquinas puedan **leer, interpretar, generar y analizar lenguaje humano** (oral o escrito).

Incluye tareas como:

-   **Tokenización**: dividir el texto en palabras, frases o unidades mínimas.

-   **Lematización/Stemming**: reducir palabras a su forma base ("corriendo" → "correr").

-   **Análisis sintáctico y semántico**: entender la estructura gramatical o el significado del texto.

-   **Extracción de entidades** (personas, lugares, organizaciones).

-   **Clasificación de sentimientos**, detección de tópicos, generación de texto, etc.

## Ciencias Sociales Computacionales: *Text Mining*

Algunos ejemplos de técnicas.

-   Modelos de tópicos (LDA) → para identificar temas latentes en discursos.

-   Análisis de sentimiento → para mapear emociones o polarización.

-   Redes semánticas → para ver cómo se asocian conceptos o actores.

-   Clasificadores supervisados → para categorizar tweets, artículos o comentarios por tipo, ideología, tono, etc.

## Ciencias Sociales Computacionales: *Text Mining*

**¿Cómo ha cambiado la forma en que los presidentes de Chile hablan sobre la *desigualdad* entre 1990 y 2021?**

-   📄 **Corpus**: Discursos anuales de la Cuenta Pública (1990–2021)\
-   🔍 **Filtro por concepto**: Palabras como `desigual*`, `brecha*`, `inequidad`, `estratificación`\
-   📊 **Conteo por año**: Número de menciones por discurso\
-   📈 **Visualización**: Gráfico de línea para mostrar evolución

**¿Por qué es útil?**

-   Convierte texto cualitativo en **datos analizables**\
-   Permite comparaciones temporales y temáticas\
-   Une teoría social y herramientas computacionales

## Fundamento en R

#### 🧰 Paquetes esenciales

-   📦 **`quanteda`**
    -   Corpus estructurados (`corpus()`, `tokens()`, `dfm()`)
    -   Análisis por diccionario (`dictionary()`, `dfm_lookup()`)
    -   KWIC y análisis de contexto (`kwic()`)
-   📦 **`tidytext`**
    -   Integración con `dplyr` para limpieza y visualización
    -   Compatible con enfoques Tidy: `count()`, `mutate()`, `group_by()`

#### 🗂️ Uso de diccionarios

-   Permite **agrupar palabras en categorías temáticas**
-   Se pueden usar para:
    -   Filtrar palabras por tema o emoción
    -   Medir frecuencia relativa o presencia/ausencia

# Conceptos y funciones fundamentales

```{r, echo=TRUE}
# Texto base
texto <- "Desde 1990 Chile es una democracia representativa y Chile 
es libre. A lo largo de su historia, Chile se 
destacó por su estabilibidad democrática, siendo la excepción la dictadura de Pinochet"
```

## Conceptos y funciones fundamentales

### 🧱 Token

> Un **token** es una unidad mínima de análisis, usualmente una palabra. Tokenizar un texto significa **dividirlo en esas unidades**.

```{r}
#| eval: true
#| echo: true

library(quanteda)
corp <- corpus(texto)
tokens(corp)


```

## 🔡 DFM (Document-Feature Matrix)

> Una **DFM** es una matriz donde cada fila representa un documento y cada columna una palabra única (token). El valor es la frecuencia.

```{r}
#| eval: true
#| echo: true


dfm(tokens(corp))
```

-   `"chile"` aparece **2 veces**

-   `"es"` aparece **2 veces**

-   Las demás palabras (`una`, `democracia`, `representativa`, `y`, `libre`, `"."`) aparecen **una vez cada una**

-   El punto `"."` fue considerado como un token separado (esto ocurre si no se removió la puntuación al crear los tokens)

## 🔡 DFM (Document-Feature Matrix): Remove punct

```{r}
#| eval: true
#| echo: true


tokens_reducidos <- tokens(corp, remove_punct = TRUE) %>%
  tokens_tolower() %>%  # pasar a minúsculas
  tokens_wordstem(language = "spanish")  # aplicar stemming

tokens_reducidos


```

## Sobre los bigramas

```{r}
#| eval: true
#| echo: true

library(tidytext)
library(tibble)
bigrama <- tibble(text = texto) %>%
  unnest_tokens(bigrama, text, token = "ngrams", n = 2)

bigrama

```

## KWIC y Stemming

### 🔍 KWIC (Key Word in Context)

> Muestra las palabras **inmediatamente antes y después** de una palabra clave. Es útil para **analizar el contexto semántico**.

```{r}
#| eval: true
#| echo: true


kwic(tokens(corp), pattern = "Chile", window = 2)

```

## Ruido de palabras

### 🚫 ¿Qué es una *Stop Word*?

> Son palabras muy frecuentes (como **"el", "de", "y", "es"**) que usualmente **no aportan significado sustantivo** al análisis textual.

### 🧠 ¿Por qué eliminarlas?

-   Aparecen en casi todos los textos → **ruido analítico**
-   No discriminan entre temas ni emociones
-   Permite centrarse en contenido más relevante (sustantivos, verbos clave)

```{r}
#| eval: true
#| echo: true


library(quanteda)

tokens_limpios <-tokens(texto,
       remove_punct = TRUE) %>%                 # Elimina puntos, comas, etc.
  tokens_tolower() %>%                          # Convierte a minúsculas
  tokens_remove(pattern = stopwords("spanish")) # Elimina stop words en español

tokens_limpios

```

## ☁️ Nube de palabras desde texto limpio

> Eliminamos puntuación y stop words para visualizar solo las palabras relevantes.

```{r}
#| eval: true
#| echo: true


library(quanteda.textplots)

# Texto más largo
texto <- "Chile es una democracia representativa. El país enfrenta desigualdades, pero también oportunidades. La educación, la salud y el trabajo son temas prioritarios para Chile."

# Limpiar y procesar
tokens_limpios <- tokens(texto,
                         remove_punct = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(pattern = stopwords("spanish"))

```

### Crear dfm (document-feature matrix)

```{r}
#| eval: true
#| echo: true

dfm_limpio <- dfm(tokens_limpios); dfm_limpio
```

## ☁️ Nube de palabras desde texto limpio

### Visualizar

```{r}
#| eval: true
#| echo: true

# Nube de palabras más rica
textplot_wordcloud(dfm_limpio, max_words = 50, min_count = 1)
```

## Diccionarios

Pensemos en un texto.

```{r}
#| echo: true
#| eval: true
library(tidytext)
library(stringr)

texto <- "La democracia es fundamental para la participación ciudadana. 
Sin embargo, la delincuencia organizada y el narcotráfico han aumentado. Se ha generado un escenario de inseguridad.
La migración también es un desafío que debe abordarse con políticas públicas integradas y garantizar derechos básicos."

```

¿Qué conceptos no pueden parecer interesantes? Definimos palabras previas.

```{r}
#| echo: true
#| eval: true

# Texto de ejemplo
texto <- "La democracia es clave. La delincuencia y el narcotráfico afectan la ciudadanía. 
Muchos migrantes y refugiados llegaron en 2023."

# Diccionario con comodines
diccionario_temas <- list(
  democracia = c("democracia", "participación", "ciudad*", "instituciones", "elecciones", "derecho*"),
  delincuencia = c("delincuencia", "crimen", "inseguridad", "violencia", "narco*"),
  migracion = c("migra*",  "refugiado", "exilio", "inmigración")
)
```

## Diccionarios

```{r}
# Tokenizar texto usando tidytext
tokens_df <- tibble(text = texto) %>%
  unnest_tokens(word, text) %>%
  filter(str_detect(word, "^[a-záéíóúñ]+$"))

```

```{r}
#| echo: true
#| eval: true

# Aplicar diccionario con comodines
patrones_democracia <- str_replace_all(diccionario_temas$democracia, "\\*", ".*")
patrones_delincuencia <- str_replace_all(diccionario_temas$delincuencia, "\\*", ".*")
patrones_migracion <- str_replace_all(diccionario_temas$migracion, "\\*", ".*")

tokens_clasificados <- tokens_df %>%
  mutate(
    tema = case_when(
      str_detect(word, regex(paste0("^(", paste(patrones_democracia, collapse = "|"), ")$"), ignore_case = TRUE)) ~ "democracia",
      str_detect(word, regex(paste0("^(", paste(patrones_delincuencia, collapse = "|"), ")$"), ignore_case = TRUE)) ~ "delincuencia",
      str_detect(word, regex(paste0("^(", paste(patrones_migracion, collapse = "|"), ")$"), ignore_case = TRUE)) ~ "migracion",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(tema)) %>%
  count(tema, word, sort = TRUE)

```

```{r}
tokens_clasificados

```

## Diccionarios

```{r}
#| echo: true
#| eval: true

library(ggplot2)

ggplot(tokens_clasificados, aes(x = reorder_within(word, n, tema), y = n, fill = tema)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ tema, scales = "free_y") +
  scale_x_reordered() +
  coord_flip() +
  labs(
    title = "Palabras clave por tema detectadas en el texto",
    subtitle = "Basado en un diccionario con comodines",
    x = NULL, y = "Frecuencia"
  ) 
```

# Vamos al código!
